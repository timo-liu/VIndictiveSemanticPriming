\begin{table*}[ht]
\centering
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lcccccccc}
\toprule
Component & Aunsiels/ChildBERT & FacebookAI/xlm-roberta-base & albert-base-v2 & bert-base-uncased & bert-large-uncased & distilbert-base-uncased & microsoft/mpnet-base & roberta-base \\
\midrule
word\_embeddings & 4.360 & -3.762 & 4.243 & -4.155 & -1.142 & -4.760 & 3.474 & -1.559 \\
encoder\_layer\_1 & \textbf{12.360}$^{*}$ & 6.904 & \textbf{8.693}$^{\dagger}$ & \textbf{4.526} & 0.547 & 3.681 & 3.592 & \textbf{12.827}$^{*}$ \\
encoder\_layer\_2 & 11.486$^{*}$ & 0.805 & 8.195$^{\dagger}$ & 4.179 & -0.383 & 2.439 & 3.226 & 10.554$^{*}$ \\
encoder\_layer\_3 & 9.906$^{*}$ & 1.971 & 6.810 & 3.353 & -1.339 & \textbf{4.084} & 2.289 & 8.505$^{\dagger}$ \\
encoder\_layer\_4 & 10.725$^{*}$ & 3.031 & 4.981 & 4.440 & -1.148 & 2.251 & 1.364 & 5.788 \\
encoder\_layer\_5 & 11.149$^{*}$ & 2.351 & 3.728 & 1.474 & 0.380 & -0.252 & 2.740 & 6.713 \\
encoder\_layer\_6 & 11.628$^{*}$ & 1.027 & 3.087 & 0.001 & 1.119 & 1.511 & 1.809 & 5.030 \\
encoder\_layer\_7 & 11.793$^{*}$ & 2.692 & 3.928 & -1.029 & 1.874 &  & 0.867 & 5.764 \\
encoder\_layer\_8 & 11.767$^{*}$ & -0.109 & 1.557 & -0.200 & 2.945 &  & -5.140 & 6.238 \\
encoder\_layer\_9 & 11.880$^{*}$ & 5.734 & 0.844 & 1.493 & \textbf{3.666} &  & 1.293 & 6.230 \\
encoder\_layer\_10 & 11.187$^{*}$ & \textbf{8.441}$^{\dagger}$ & 1.708 & 1.634 & 2.368 &  & 2.778 & 5.708 \\
encoder\_layer\_11 & 10.517$^{*}$ & 6.863 & 2.306 & 2.349 & 0.717 &  & -0.732 & 8.868$^{\dagger}$ \\
encoder\_layer\_12 & 10.114$^{*}$ & 4.865 & 4.730 & -0.755 & -0.552 &  & \textbf{6.046} & 10.017$^{*}$ \\
\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Spearman $\rho$ between cosine similarity and RT (LDT, relation associated, ISI=1050 ms). $^*$ $p<.01$, $^\dagger$ $.01\leq p \leq .05$. Bold = largest value within model.}
\label{tab:ldt_relassociated_isi1050}
\end{table*}
