\begin{table}[ht]
\centering
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lccccccc}
\toprule
Component & Aunsiels/ChildBERT & FacebookAI/xlm-roberta-base & albert-base-v2 & bert-base-uncased & distilbert-base-uncased & microsoft/mpnet-base & roberta-base \\
\midrule
word\_embeddings & 0.024 & 0.038 & 0.016 & 0.075$^{\dagger}$ & 0.073$^{\dagger}$ & 0.024 & 0.029 \\
encoder\_layer\_1 & -0.063$^{\dagger}$ & -0.070$^{\dagger}$ &  & -0.020 & -0.015 & -0.034 & -0.022 \\
encoder\_layer\_2 & -0.054 & -0.018 &  & -0.030 & -0.016 & -0.032 & -0.014 \\
encoder\_layer\_3 & -0.054 & -0.023 &  & -0.032 & -0.011 & -0.033 & -0.002 \\
encoder\_layer\_4 & -0.055 & -0.025 &  & -0.031 & -0.005 & -0.027 & 0.014 \\
encoder\_layer\_5 & -0.058 & -0.026 &  & 0.002 & 0.006 & -0.022 & 0.011 \\
encoder\_layer\_6 & -0.056 & -0.024 &  & 0.021 & -0.006 & -0.025 & 0.016 \\
encoder\_layer\_7 & -0.058 & -0.010 &  & 0.024 &  & -0.024 & 0.011 \\
encoder\_layer\_8 & -0.058 & -0.016 &  & 0.030 &  & -0.026 & 0.016 \\
encoder\_layer\_9 & -0.059 & -0.039 &  & 0.029 &  & -0.036 & 0.012 \\
encoder\_layer\_10 & -0.058 & -0.051 &  & 0.028 &  & -0.052 & -0.006 \\
encoder\_layer\_11 & -0.052 & -0.027 &  & 0.035 &  & -0.015 & -0.012 \\
encoder\_layer\_12 & -0.050 & -0.046 &  & 0.042 &  & -0.042 & -0.014 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Spearman $\rho$ between cosine similarity and RT (LDT, relation unclassified, ISI=1050 ms). $^*$ $p<.01$, $^\dagger$ $.01\leq p \leq .05$.}
\label{tab:ldt_relunclassified_isi1050}
\end{table}
