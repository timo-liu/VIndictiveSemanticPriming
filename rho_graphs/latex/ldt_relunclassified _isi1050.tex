\begin{table}[ht]
\centering
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lccccccc}
\toprule
Component & Aunsiels/ChildBERT & FacebookAI/xlm-roberta-base & albert-base-v2 & bert-base-uncased & distilbert-base-uncased & microsoft/mpnet-base & roberta-base \\
\midrule
word\_embeddings & -0.008 & 0.107 & -0.090 & 0.020 & 0.018 & -0.083 & 0.089 \\
encoder\_layer\_1 & -0.105 & -0.087 &  & -0.118 & -0.102 & -0.093 & -0.105 \\
encoder\_layer\_2 & -0.110 & -0.067 &  & -0.136 & -0.044 & -0.070 & -0.099 \\
encoder\_layer\_3 & -0.103 & -0.059 &  & -0.130 & -0.046 & -0.049 & -0.093 \\
encoder\_layer\_4 & -0.118 & -0.046 &  & -0.124 & -0.044 & -0.022 & -0.067 \\
encoder\_layer\_5 & -0.117 & -0.046 &  & -0.037 & -0.004 & -0.031 & -0.050 \\
encoder\_layer\_6 & -0.113 & -0.066 &  & -0.009 & -0.004 & -0.040 & -0.037 \\
encoder\_layer\_7 & -0.115 & -0.014 &  & 0.053 &  & -0.031 & -0.035 \\
encoder\_layer\_8 & -0.112 & -0.040 &  & 0.082 &  & 0.011 & -0.027 \\
encoder\_layer\_9 & -0.091 & -0.073 &  & 0.079 &  & -0.074 & -0.033 \\
encoder\_layer\_10 & -0.092 & -0.090 &  & 0.091 &  & -0.006 & -0.068 \\
encoder\_layer\_11 & -0.091 & -0.096 &  & 0.102 &  & 0.058 & -0.057 \\
encoder\_layer\_12 & -0.107 & -0.066 &  & 0.122 &  & -0.065 & -0.057 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Spearman $\rho$ between cosine similarity and RT (LDT, relation unclassified , ISI=1050 ms). $^*$ $p<.01$, $^\dagger$ $.01\leq p \leq .05$.}
\label{tab:ldt_relunclassified _isi1050}
\end{table}
