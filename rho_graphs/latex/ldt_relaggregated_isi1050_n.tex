\begin{table}[ht]
\centering
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lccccccc}
\toprule
Component & Aunsiels/ChildBERT & FacebookAI/xlm-roberta-base & albert-base-v2 & bert-base-uncased & distilbert-base-uncased & microsoft/mpnet-base & roberta-base \\
\midrule
word\_embeddings & 59098 & 59098 & 59098 & 78681 & 78681 & 59098 & 78681 \\
encoder\_layer\_1 & 59098 & 59098 & 59098 & 78681 & 78681 & 59098 & 78681 \\
encoder\_layer\_2 & 59098 & 59098 & 59098 & 78681 & 78681 & 59098 & 78681 \\
encoder\_layer\_3 & 59098 & 59098 & 59098 & 78681 & 78681 & 59098 & 78681 \\
encoder\_layer\_4 & 59098 & 59098 & 59098 & 78681 & 78681 & 59098 & 78681 \\
encoder\_layer\_5 & 59098 & 59098 & 59098 & 78681 & 78681 & 59098 & 78681 \\
encoder\_layer\_6 & 59098 & 59098 & 59098 & 78681 & 59098 & 59098 & 78681 \\
encoder\_layer\_7 & 59098 & 59098 & 59098 & 78681 &  & 59098 & 78681 \\
encoder\_layer\_8 & 59098 & 59098 & 59098 & 78681 &  & 59098 & 78681 \\
encoder\_layer\_9 & 59098 & 59098 & 59098 & 78681 &  & 59098 & 78681 \\
encoder\_layer\_10 & 59098 & 59098 & 59098 & 78681 &  & 59098 & 78681 \\
encoder\_layer\_11 & 59098 & 59098 & 59098 & 78681 &  & 59098 & 78681 \\
encoder\_layer\_12 & 59098 & 59098 & 59098 & 78681 &  & 59098 & 78681 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Number of observations ($n$) used for Spearman $\rho$ (LDT, relation aggregated, ISI=1050 ms).}
\label{tab:ldt_relaggregated_isi1050_n}
\end{table}
